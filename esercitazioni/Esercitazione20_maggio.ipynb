{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fe14f5e-f4e8-45db-a61f-be34bc5ebee8",
   "metadata": {},
   "source": [
    "## Esercitazione del 20 Maggio 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b4ad6e-adec-42e2-8470-e17c17f7ec4b",
   "metadata": {},
   "source": [
    "# Esercizio 1\n",
    "\n",
    "Scrivere un codice Python per l'addestramento di una rete MLP  per risolvere un problema di regressione. La rete ha la seguente architettura: un layer di input formato da un solo neurone e un layer di output formato da un solo neurone.\n",
    "\n",
    "**Algoritmo di addestramento:**\n",
    "\n",
    "Utilizzeremo l'algoritmo di ottimizzazione Batch Gradient Descent con passo di apprendimento learning_rate per aggiornare i pesi della rete durante l'addestramento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7102b93e-2eee-4ebb-9de9-8e16da345326",
   "metadata": {},
   "source": [
    "## Descrizione del problema:\n",
    "\n",
    "Consideriamo un dataset di coppie (x, y), dove x è un valore di input scalare e y è il valore di output desiderato. La rete MLP deve apprendere la relazione tra x e y in modo da poter prevedere y per nuovi valori di x."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17175e12-bfc0-4d34-a0b1-55b381e86080",
   "metadata": {},
   "source": [
    "-   Implementare la  funzione forward_propagation che calcola    l'output della rete per un dato input x.\n",
    "-   Implementare la  funzione backward_propagation per calcolare il gradiente della funzione di perdita rispetto ai pesi della rete ed aggiornare i pesi con il metodo del  Gradient Descent.\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4225d6-47c5-406f-bf9c-2eac836e1a99",
   "metadata": {},
   "source": [
    "Addestrare la rete:\n",
    "\n",
    "-     Caricare un dataset di coppie (x, y).\n",
    "-     Inizializzare i pesi della rete con valori casuali.\n",
    "-     Iterare su un numero definito di epoche:\n",
    "        Per ogni campione di training (x, y):\n",
    "          -  Calcolare l'output previsto y_pred\n",
    "             (forward_propagation).\n",
    "        Calcolare l'errore MSE (np.mean(0.5*(y_pred - y)**2)\n",
    "         -Calcolare il gradiente della funzione Costo\n",
    "           rispetto ai pesi (backward_propagation).\n",
    "         -Aggiornare i pesi della rete utilizzando\n",
    "          l'algoritmo di Batch Gradient Descent.\n",
    "\n",
    "   \n",
    "-    Sperimentare con diversi valori di learning rate e numero di\n",
    "     epoche per ottimizzare le prestazioni della rete.\n",
    "\n",
    "-    Visualizzare il grafico della Cost-Function in funzione delle epoche\n",
    "\n",
    "-    Usa la funzione di attivazione RELU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea306b4-e61e-474a-b24b-dd56bd797aa6",
   "metadata": {},
   "source": [
    "Valutare le prestazioni della rete:\n",
    "-    Su un set di dati di test e  Visualizzare i risultati ottenuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06a4caa3-3dbc-4f6d-a4db-038e0659f994",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "seed=11\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "def relu(x):\n",
    "  \"\"\"\n",
    "\n",
    "  Argomenti:\n",
    "    x: Valore di input.\n",
    "\n",
    "  Restituisce:\n",
    "    Valore di output della funzione ReLU.\n",
    "  \"\"\"\n",
    "  return np.where(x >= 0, x, 0)\n",
    "\n",
    "def relu_derivative(x):\n",
    "  \"\"\"\n",
    "  Funzione per calcolare la derivata vettoriale della funzione ReLU.\n",
    "\n",
    "  Argomenti:\n",
    "    x: Array di input.\n",
    "\n",
    "  Restituisce:\n",
    "    Array contenente la derivata della funzione ReLU per ogni elemento in x.\n",
    "  \"\"\"\n",
    "  return np.where(x >= 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306bdd8d-cef3-4852-ac79-c11993fa2637",
   "metadata": {},
   "source": [
    "# Esercizio 2\n",
    "\n",
    "Risolvere lo stesso problema cambiando l'architettura della rete:\n",
    "\n",
    "La rete MLP avrà la seguente struttura:\n",
    "\n",
    "    1 layer di input formato da un solo neurone che riceve il valore di x\n",
    "    2 hidden layers ognuno formato da un solo neurone con funzione di attivazione ReLU\n",
    "    1 layer di output formato da un solo neurone che produce il valore previsto di y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ec1855-2a0a-4c78-a1d2-97d92f44a12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrare in vecchio codice scritto l'altra volta\n",
    "\n",
    "def forward_propagation(x,w,b):\n",
    "    a1=w[0]*x+b[0]\n",
    "    z1=relu(a1)\n",
    "\n",
    "    a2=w[1]*z1+b[1]\n",
    "    z2=relu(a2)\n",
    "\n",
    "    a3=w[2]*z2+b[2]\n",
    "    z3=relu(a3)\n",
    "\n",
    "    return z3,a1,a2,a3,z1,z2\n",
    "\n",
    "def backward_propagation(y_pred,y,w,b,a1,a2,a3,z1,z2,x,learning_rate):\n",
    "    delta_3=(y_pred-y)*relu_derivative(a3)\n",
    "    delta_2=delta_3*w[2]*relu_derivative(a2)\n",
    "    delta_1=delta_2*w[1]*relu_derivative(a1)\n",
    "\n",
    "    #Aggiornamento dei pesi\n",
    "    w[2]=w[2]-learning_rate*np.sum(delta_3*z2)/nT\n",
    "    w[1]=w[1]-learning_rate*np.sum(delta_2*z1)/nT\n",
    "    w[0]=w[0]-learning_rate*np.sum(delta_1*x)/nT\n",
    "\n",
    "    #Aggiornamento bias\n",
    "    b[2]=b[2]-learning_rate*np.sum(delta_3)/nT\n",
    "    b[1]=b[1]-learning_rate*np.sum(delta_2)/nT\n",
    "    b[0]=b[0]-learning_rate*np.sum(delta_1)/nT\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e48d2180-a776-4ff4-a452-c8cc8f57089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w=np.random.randn(3)\n",
    "b=np.random.randn(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "93b67121-5da0-4124-af6d-2f9a258970f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nT\u001b[38;5;241m=\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      2\u001b[0m f_loss_1\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#Predizione\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "nT=x.shape[0]\n",
    "f_loss_1=[]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Predizione\n",
    "    y_pred,a1,a2,a3,z1,z2=forward_propagation(x,w,b)\n",
    "    #Calcola la funzione costo\n",
    "    loss=mse(y_pred,y)\n",
    "    f_loss_1.append(loss)\n",
    "    w,b=backward_propagation(y_pred,y,w,b,a1,a2,a3,z1,z2,x,learning_rate,nT)\n",
    "\n",
    "#Predizione sui nuovi dati\n",
    "xnew=np.linspace(0.0,10,100)\n",
    "y_pred_new,a1,a2,a3,z1,z2=forward_propagation(xnew,w,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d225971d-2603-4f38-afec-779a1743b8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x,y,xnew,y_pred_new,'r-')\n",
    "plt.show()\n",
    "plt.semilogy(f_loss_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fd0032-6356-4b53-9791-12154584c069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b855c50f-13de-45a7-91ff-021a7c76fce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed50d613-2d33-4cae-b20d-470d6fbc7545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1987a4d2-3fc2-4df5-93e7-df689a66073c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a56d6e-3173-4580-8d22-0d540955d3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af197a6-8eb3-4cbf-abd2-50000edc86b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
